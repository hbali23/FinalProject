[
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "EDA",
    "section": "",
    "text": "The Behavioral Risk Factor Surveillance System (BRFSS) is an annual health-related telephone survey conducted by the CDC, collecting responses from over 400,000 Americans on health behaviors, chronic conditions, and preventative service use since 1984. For this project, trhe dataset diabetes_binary_health_indicators_BRFSS2015.csv contains 253,680 survey responses from the CDC’s BRFSS 2015. The target variable, Diabetes_binary, has two classes: 0: No diabetes and 1: Prediabetes or diabetes. The dataset has 22 featured variables. In my analysis, I will look into all of the variables except for Diabetes_binary. The variables that will be used in the EDA are the following; HighBP, HighChol, CholCheck, BMI, Smoker, Stroke, HeartDiseaseorAttack, PhysActivity, Fruits, Veggies, HvyAlcoholConsump, AnyHealthcare, NoDocbcCost, GenHlth, MentHlth, PhysHlth, DiffWalk, Sex, Age, Education, and Income.\nThe primary purpose of EDA is to understand the data and its structure, identify patterns, spot anomalies, test hypotheses, and check assumptions. This helps in selecting the right modeling techniques and ensures that the data is clean and suitable for analysis. For this analysis, the ultimate goal of modeling is to build a robust and accurate predictive model that can classify individuals into the two categories of the Diabetes_binary variable (0: No diabetes, 1: Prediabetes or diabetes). This model can then be used to identify individuals at risk and potentially guide public health interventions and strategies."
  },
  {
    "objectID": "EDA.html#introduction",
    "href": "EDA.html#introduction",
    "title": "EDA",
    "section": "",
    "text": "The Behavioral Risk Factor Surveillance System (BRFSS) is an annual health-related telephone survey conducted by the CDC, collecting responses from over 400,000 Americans on health behaviors, chronic conditions, and preventative service use since 1984. For this project, trhe dataset diabetes_binary_health_indicators_BRFSS2015.csv contains 253,680 survey responses from the CDC’s BRFSS 2015. The target variable, Diabetes_binary, has two classes: 0: No diabetes and 1: Prediabetes or diabetes. The dataset has 22 featured variables. In my analysis, I will look into all of the variables except for Diabetes_binary. The variables that will be used in the EDA are the following; HighBP, HighChol, CholCheck, BMI, Smoker, Stroke, HeartDiseaseorAttack, PhysActivity, Fruits, Veggies, HvyAlcoholConsump, AnyHealthcare, NoDocbcCost, GenHlth, MentHlth, PhysHlth, DiffWalk, Sex, Age, Education, and Income.\nThe primary purpose of EDA is to understand the data and its structure, identify patterns, spot anomalies, test hypotheses, and check assumptions. This helps in selecting the right modeling techniques and ensures that the data is clean and suitable for analysis. For this analysis, the ultimate goal of modeling is to build a robust and accurate predictive model that can classify individuals into the two categories of the Diabetes_binary variable (0: No diabetes, 1: Prediabetes or diabetes). This model can then be used to identify individuals at risk and potentially guide public health interventions and strategies."
  },
  {
    "objectID": "EDA.html#data",
    "href": "EDA.html#data",
    "title": "EDA",
    "section": "Data",
    "text": "Data\nUse a relative path to import the data. You likely want to convert a lot of the variables to factors with meaningful level names. Check on missingness, etc\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr)\nlibrary(readxl)\n\n\n# Import the data\ndiabetes_data &lt;- read_excel(\"~/Downloads/diabetes_binary_health_indicators_BRFSS2015.xlsm\")\n\n# Convert variables to factors\ndiabetes_data$Diabetes_binary &lt;- factor(diabetes_data$Diabetes_binary, levels = c(0, 1), labels = c(\"No Diabetes\", \"Prediabetes or Diabetes\"))\ndiabetes_data$HighBP &lt;- factor(diabetes_data$HighBP, levels = c(0, 1), labels = c(\"No\", \"Yes\"))\ndiabetes_data$HighChol &lt;- factor(diabetes_data$HighChol, levels = c(0, 1), labels = c(\"No\", \"Yes\"))\ndiabetes_data$CholCheck &lt;- factor(diabetes_data$CholCheck, levels = c(0, 1), labels = c(\"No\", \"Yes\"))\ndiabetes_data$Smoker &lt;- factor(diabetes_data$Smoker, levels = c(0, 1), labels = c(\"No\", \"Yes\"))\ndiabetes_data$Stroke &lt;- factor(diabetes_data$Stroke, levels = c(0, 1), labels = c(\"No\", \"Yes\"))\ndiabetes_data$HeartDiseaseorAttack &lt;- factor(diabetes_data$HeartDiseaseorAttack, levels = c(0, 1), labels = c(\"No\", \"Yes\"))\ndiabetes_data$PhysActivity &lt;- factor(diabetes_data$PhysActivity, levels = c(0, 1), labels = c(\"No\", \"Yes\"))\ndiabetes_data$Fruits &lt;- factor(diabetes_data$Fruits, levels = c(0, 1), labels = c(\"No\", \"Yes\"))\ndiabetes_data$Veggies &lt;- factor(diabetes_data$Veggies, levels = c(0, 1), labels = c(\"No\", \"Yes\"))\ndiabetes_data$HvyAlcoholConsump &lt;- factor(diabetes_data$HvyAlcoholConsump, levels = c(0, 1), labels = c(\"No\", \"Yes\"))\ndiabetes_data$AnyHealthcare &lt;- factor(diabetes_data$AnyHealthcare, levels = c(0, 1), labels = c(\"No\", \"Yes\"))\ndiabetes_data$NoDocbcCost &lt;- factor(diabetes_data$NoDocbcCost, levels = c(0, 1), labels = c(\"No\", \"Yes\"))\ndiabetes_data$DiffWalk &lt;- factor(diabetes_data$DiffWalk, levels = c(0, 1), labels = c(\"No\", \"Yes\"))\ndiabetes_data$Sex &lt;- factor(diabetes_data$Sex, levels = c(0, 1), labels = c(\"Male\", \"Female\"))\ndiabetes_data$GenHlth &lt;- factor(diabetes_data$GenHlth, levels = 1:5, labels = c(\"Excellent\", \"Very Good\", \"Good\", \"Fair\", \"Poor\"))\n\n# Convert Age, Education, and Income to factors with meaningful level names\ndiabetes_data$Age &lt;- factor(diabetes_data$Age, levels = 1:13, labels = c(\"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\", \"45-49\", \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\", \"75-79\", \"80 or older\"))\ndiabetes_data$Education &lt;- factor(diabetes_data$Education, levels = 1:6, labels = c(\"Never attended school\", \"Elementary\", \"Some high school\", \"High school graduate\", \"Some college\", \"College graduate\"))\ndiabetes_data$Income &lt;- factor(diabetes_data$Income, levels = 1:8, labels = c(\"Less than $10,000\", \"$10,000-$14,999\", \"$15,000-$19,999\", \"$20,000-$24,999\", \"$25,000-$34,999\", \"$35,000-$49,999\", \"$50,000-$74,999\", \"$75,000 or more\"))\n\n# Check for missing values\nmissing_values &lt;- sapply(diabetes_data, function(x) sum(is.na(x)))\n\n# Summary of the dataset\nsummary(diabetes_data)\n\n                Diabetes_binary   HighBP       HighChol     CholCheck   \n No Diabetes            :218334   No :144851   No :146089   No :  9470  \n Prediabetes or Diabetes: 35346   Yes:108829   Yes:107591   Yes:244210  \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n      BMI        Smoker       Stroke       HeartDiseaseorAttack PhysActivity\n Min.   :12.00   No :141257   No :243388   No :229787           No : 61760  \n 1st Qu.:24.00   Yes:112423   Yes: 10292   Yes: 23893           Yes:191920  \n Median :27.00                                                              \n Mean   :28.38                                                              \n 3rd Qu.:31.00                                                              \n Max.   :98.00                                                              \n                                                                            \n Fruits       Veggies      HvyAlcoholConsump AnyHealthcare NoDocbcCost \n No : 92782   No : 47839   No :239424        No : 12417    No :232326  \n Yes:160898   Yes:205841   Yes: 14256        Yes:241263    Yes: 21354  \n                                                                       \n                                                                       \n                                                                       \n                                                                       \n                                                                       \n      GenHlth         MentHlth         PhysHlth      DiffWalk    \n Excellent:45299   Min.   : 0.000   Min.   : 0.000   No :211005  \n Very Good:89084   1st Qu.: 0.000   1st Qu.: 0.000   Yes: 42675  \n Good     :75646   Median : 0.000   Median : 0.000               \n Fair     :31570   Mean   : 3.185   Mean   : 4.242               \n Poor     :12081   3rd Qu.: 2.000   3rd Qu.: 3.000               \n                   Max.   :30.000   Max.   :30.000               \n                                                                 \n     Sex              Age                        Education     \n Male  :141974   60-64  :33244   Never attended school:   174  \n Female:111706   65-69  :32194   Elementary           :  4043  \n                 55-59  :30832   Some high school     :  9478  \n                 50-54  :26314   High school graduate : 62750  \n                 70-74  :23533   Some college         : 69910  \n                 45-49  :19819   College graduate     :107325  \n                 (Other):87744                                 \n             Income     \n $75,000 or more:90385  \n $50,000-$74,999:43219  \n $35,000-$49,999:36470  \n $25,000-$34,999:25883  \n $20,000-$24,999:20135  \n $15,000-$19,999:15994  \n (Other)        :21594"
  },
  {
    "objectID": "EDA.html#summarizations",
    "href": "EDA.html#summarizations",
    "title": "EDA",
    "section": "Summarizations",
    "text": "Summarizations\nYou should then produce meaningful summary statistics and plots about the data you are working with (especially as it relates to your response).\nAlthough a best practice would be to split the data at hand into a training and testing set first, go ahead and do your EDA on the full data.\nBe sure to have a narrative about what you are exploring and what the summaries and graphs you created say about the relationships in your data.\nDistribution of Target Variable The distribution plot of the Diabetes_binary variable shows the count of individuals with and without diabetes. This plot indicates the prevalence of diabetes in the dataset.\n\n# Bar plot for the target variable\nggplot(diabetes_data, aes(x = Diabetes_binary)) +\n  geom_bar(fill = \"blue\", color = \"black\") +\n  ggtitle(\"Distribution of Diabetes Status\") +\n  xlab(\"Diabetes Status\") +\n  ylab(\"Count\")\n\n\n\n\n\n\n\n\nDistribution of BMI The histogram of BMI by diabetes status shows how BMI values are distributed among individuals with and without diabetes. Typically, higher BMI values are associated with a greater risk of diabetes, and we expect to see a higher concentration of diabetes cases in the higher BMI ranges.\n\n# Histogram of BMI\nggplot(diabetes_data, aes(x = BMI, fill = Diabetes_binary)) +\n  geom_histogram(binwidth = 1, position = \"dodge\", color = \"black\") +\n  ggtitle(\"Distribution of BMI by Diabetes Status\") +\n  xlab(\"BMI\") +\n  ylab(\"Count\") +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\nRelationship Between Age and Diabetes Status The bar plot of age distribution by diabetes status helps us understand how age influences the likelihood of diabetes. We expect older age groups to have a higher prevalence of diabetes.\n\n# Bar plot for Age distribution by Diabetes Status\nggplot(diabetes_data, aes(x = Age, fill = Diabetes_binary)) +\n  geom_bar(position = \"dodge\", color = \"black\") +\n  ggtitle(\"Age Distribution by Diabetes Status\") +\n  xlab(\"Age Group\") +\n  ylab(\"Count\") +\n  scale_fill_manual(values = c(\"blue\", \"red\")) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nRelationship Between Physical Activity and Diabetes Status The bar plot for physical activity by diabetes status shows the impact of physical activity on diabetes risk. Regular physical activity is expected to be associated with a lower risk of diabetes.\n\n# Bar plot for Physical Activity by Diabetes Status\nggplot(diabetes_data, aes(x = PhysActivity, fill = Diabetes_binary)) +\n  geom_bar(position = \"dodge\", color = \"black\") +\n  ggtitle(\"Physical Activity by Diabetes Status\") +\n  xlab(\"Physical Activity\") +\n  ylab(\"Count\") +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\nProportion of Diabetes by Gender and Proportion of Diabetes by General Health. The proportion table shows the distribution of diabetes status by gender. This can help understand if there is a significant difference in diabetes prevalence between males and females.\nThe proportion table for general health by diabetes status indicates how self-reported health status correlates with diabetes. Poor general health is likely associated with a higher prevalence of diabetes\n\n# Proportion of diabetes by gender\nprop_table_gender &lt;- prop.table(table(diabetes_data$Sex, diabetes_data$Diabetes_binary), margin = 1)\nprint(prop_table_gender)\n\n        \n         No Diabetes Prediabetes or Diabetes\n  Male     0.8703213               0.1296787\n  Female   0.8483967               0.1516033\n\n# Proportion of diabetes by general health\nprop_table_genhlth &lt;- prop.table(table(diabetes_data$GenHlth, diabetes_data$Diabetes_binary), margin = 1)\nprint(prop_table_genhlth)\n\n           \n            No Diabetes Prediabetes or Diabetes\n  Excellent  0.97483388              0.02516612\n  Very Good  0.92837098              0.07162902\n  Good       0.82210560              0.17789440\n  Fair       0.68989547              0.31010453\n  Poor       0.62105786              0.37894214\n\n\nDistribution of General Health by Diabetes Status The bar plot for general health by diabetes status visualizes the relationship between self-reported health status and diabetes. We expect to see poorer health statuses associated with a higher prevalence of diabetes.\n\n# Bar plot for General Health by Diabetes Status\nggplot(diabetes_data, aes(x = GenHlth, fill = Diabetes_binary)) +\n  geom_bar(position = \"dodge\", color = \"black\") +\n  ggtitle(\"General Health by Diabetes Status\") +\n  xlab(\"General Health\") +\n  ylab(\"Count\") +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\nRelationship Between High Blood Pressure and Diabetes Status The bar plot for high blood pressure by diabetes status shows the correlation between hypertension and diabetes. High blood pressure is a known risk factor for diabetes.\n\n# Bar plot for High Blood Pressure by Diabetes Status\nggplot(diabetes_data, aes(x = HighBP, fill = Diabetes_binary)) +\n  geom_bar(position = \"dodge\", color = \"black\") +\n  ggtitle(\"High Blood Pressure by Diabetes Status\") +\n  xlab(\"High Blood Pressure\") +\n  ylab(\"Count\") +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\nRelationship Between High Cholesterol and Diabetes Status The bar plot for high cholesterol by diabetes status illustrates the relationship between cholesterol levels and diabetes. High cholesterol is often associated with diabetes.\n\n# Bar plot for High Cholesterol by Diabetes Status\nggplot(diabetes_data, aes(x = HighChol, fill = Diabetes_binary)) +\n  geom_bar(position = \"dodge\", color = \"black\") +\n  ggtitle(\"High Cholesterol by Diabetes Status\") +\n  xlab(\"High Cholesterol\") +\n  ylab(\"Count\") +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\nRelationship Between Smoking and Diabetes Status The bar plot for smoking by diabetes status shows how smoking status relates to diabetes. Smoking is a risk factor for many chronic diseases, including diabetes.\n\n# Bar plot for Smoking by Diabetes Status\nggplot(diabetes_data, aes(x = Smoker, fill = Diabetes_binary)) +\n  geom_bar(position = \"dodge\", color = \"black\") +\n  ggtitle(\"Smoking by Diabetes Status\") +\n  xlab(\"Smoking Status\") +\n  ylab(\"Count\") +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\nConclusion By analyzing these summary statistics and visualizations, we gain insights into how various factors like BMI, age, and physical activity are related to diabetes. This understanding helps in building a predictive model to identify individuals at risk of diabetes effectively. Further analysis can include more variables and interaction effects to improve model accuracy.\nThese additional summary statistics and visualizations provide further insights into how various health-related factors are associated with diabetes. Understanding these relationships is crucial for building a predictive model that can accurately identify individuals at risk of diabetes. By exploring these variables in depth, we can improve the model’s accuracy and reliability.\nADD THE LINK HERE TO CONNECT TO MODELLING WHEN DONE AND GIVE MORE INSIGHT TO THE TAKEAWAYS OF THE EDA AND Be sure to have a narrative about what you are exploring and what the summaries and graphs you created say about the relationships in your data!!!"
  },
  {
    "objectID": "Modelling.html",
    "href": "Modelling.html",
    "title": "Modelling",
    "section": "",
    "text": "Log loss, also known as logistic loss or cross-entropy loss, is a performance metric used to evaluate the accuracy of a classification model, particularly in binary classification problems. It measures the uncertainty of the predictions made by the model, by comparing the predicted probabilities of the target variable to the actual binary outcomes. Log loss penalizes incorrect predictions more heavily when they are confident but wrong, and it rewards correct predictions that are confident. This makes log loss a more nuanced measure than accuracy, which simply calculates the proportion of correct predictions.\nLog loss is particularly useful when dealing with imbalanced datasets, where one class may be significantly more prevalent than the other. In such cases, a model could achieve high accuracy by merely predicting the majority class, but this would not necessarily reflect the model’s true performance in distinguishing between the classes. Log loss addresses this by taking into account the predicted probabilities, ensuring that the model not only predicts the correct class but also assigns a high probability to its predictions. This makes log loss a preferred metric for evaluating models in scenarios where the cost of false positives and false negatives is high, or where we need to understand the confidence of the model’s predictions.\n\n# Load necessary libraries\nlibrary(caret)\n\nLoading required package: ggplot2\n\n\nLoading required package: lattice\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tibble)\nlibrary(readxl)\nlibrary(tidyr)\nlibrary(rpart)\nlibrary(randomForest)\n\nrandomForest 4.7-1.1\n\n\nType rfNews() to see new features/changes/bug fixes.\n\n\n\nAttaching package: 'randomForest'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\nThe following object is masked from 'package:ggplot2':\n\n    margin\n\nlibrary(rpart.plot)\nlibrary(doParallel)  # For parallel processing\n\nLoading required package: foreach\n\n\nLoading required package: iterators\n\n\nLoading required package: parallel\n\nlibrary(parallel)    # For detectCores()\nlibrary(e1071)"
  },
  {
    "objectID": "Modelling.html#basic-introduction-start-with-a-basic-introduction-feel-free-to-repeat-some-things-from-the-other-file.",
    "href": "Modelling.html#basic-introduction-start-with-a-basic-introduction-feel-free-to-repeat-some-things-from-the-other-file.",
    "title": "Modelling",
    "section": "",
    "text": "Log loss, also known as logistic loss or cross-entropy loss, is a performance metric used to evaluate the accuracy of a classification model, particularly in binary classification problems. It measures the uncertainty of the predictions made by the model, by comparing the predicted probabilities of the target variable to the actual binary outcomes. Log loss penalizes incorrect predictions more heavily when they are confident but wrong, and it rewards correct predictions that are confident. This makes log loss a more nuanced measure than accuracy, which simply calculates the proportion of correct predictions.\nLog loss is particularly useful when dealing with imbalanced datasets, where one class may be significantly more prevalent than the other. In such cases, a model could achieve high accuracy by merely predicting the majority class, but this would not necessarily reflect the model’s true performance in distinguishing between the classes. Log loss addresses this by taking into account the predicted probabilities, ensuring that the model not only predicts the correct class but also assigns a high probability to its predictions. This makes log loss a preferred metric for evaluating models in scenarios where the cost of false positives and false negatives is high, or where we need to understand the confidence of the model’s predictions.\n\n# Load necessary libraries\nlibrary(caret)\n\nLoading required package: ggplot2\n\n\nLoading required package: lattice\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tibble)\nlibrary(readxl)\nlibrary(tidyr)\nlibrary(rpart)\nlibrary(randomForest)\n\nrandomForest 4.7-1.1\n\n\nType rfNews() to see new features/changes/bug fixes.\n\n\n\nAttaching package: 'randomForest'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\nThe following object is masked from 'package:ggplot2':\n\n    margin\n\nlibrary(rpart.plot)\nlibrary(doParallel)  # For parallel processing\n\nLoading required package: foreach\n\n\nLoading required package: iterators\n\n\nLoading required package: parallel\n\nlibrary(parallel)    # For detectCores()\nlibrary(e1071)"
  },
  {
    "objectID": "Modelling.html#adjust-factor-levels-and-set-up-cross-validation-and-log-loss-metric",
    "href": "Modelling.html#adjust-factor-levels-and-set-up-cross-validation-and-log-loss-metric",
    "title": "Modelling",
    "section": "Adjust Factor Levels and Set Up Cross-Validation and Log Loss Metric",
    "text": "Adjust Factor Levels and Set Up Cross-Validation and Log Loss Metric\n\n# Import the data\ndiabetes_data &lt;- read_excel(\"~/Downloads/diabetes_binary_health_indicators_BRFSS2015.xlsm\")\n\n# Convert Diabetes_binary to a factor with two levels\ndiabetes_data$Diabetes_binary &lt;- factor(diabetes_data$Diabetes_binary, levels = c(0, 1))\n\n# Ensure that the factor levels have valid R names\nlevels(diabetes_data$Diabetes_binary) &lt;- make.names(levels(diabetes_data$Diabetes_binary))\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Split the data into training (70%) and test (30%) sets\ntrainIndex &lt;- createDataPartition(diabetes_data$Diabetes_binary, p = 0.7, list = FALSE)\ntrainData &lt;- diabetes_data[trainIndex, ]\ntestData &lt;- diabetes_data[-trainIndex, ]\n\n# Define training control with 5-fold cross-validation and log loss as the metric\ntrain_control &lt;- trainControl(method = \"cv\", number = 5, classProbs = TRUE, summaryFunction = mnLogLoss)"
  },
  {
    "objectID": "Modelling.html#model-1-basic-logistic-regression-with-no-additional-features.",
    "href": "Modelling.html#model-1-basic-logistic-regression-with-no-additional-features.",
    "title": "Modelling",
    "section": "Model 1: Basic logistic regression with no additional features.",
    "text": "Model 1: Basic logistic regression with no additional features.\n\n# Model 1: Basic Logistic Regression\nmodel1 &lt;- train(Diabetes_binary ~ ., data = trainData, method = \"glm\", family = \"binomial\",\n                trControl = train_control, metric = \"logLoss\")"
  },
  {
    "objectID": "Modelling.html#model-2-logistic-regression-with-interaction-terms.",
    "href": "Modelling.html#model-2-logistic-regression-with-interaction-terms.",
    "title": "Modelling",
    "section": "Model 2: Logistic regression with interaction terms.",
    "text": "Model 2: Logistic regression with interaction terms.\n\n# Model 2: Logistic Regression with only select few cardiohealth terms\nformula_interaction &lt;- Diabetes_binary ~ HighBP + HighChol + CholCheck + BMI + Smoker + Stroke + HeartDiseaseorAttack \nmodel2 &lt;- train(formula_interaction, data = trainData, method = \"glm\", family = \"binomial\",\n                trControl = train_control, metric = \"logLoss\")"
  },
  {
    "objectID": "Modelling.html#model-3-logistic-regression-with-polynomial-terms.",
    "href": "Modelling.html#model-3-logistic-regression-with-polynomial-terms.",
    "title": "Modelling",
    "section": "Model 3: Logistic regression with polynomial terms.",
    "text": "Model 3: Logistic regression with polynomial terms.\n\n# Model 3: Logistic Regression with Polynomial Terms with all terms\nformula_polynomial &lt;- Diabetes_binary ~ poly(BMI, 2) + poly(Age, 2) + HighBP + HighChol + CholCheck + Smoker + Stroke + HeartDiseaseorAttack + PhysActivity + Fruits + Veggies + HvyAlcoholConsump + AnyHealthcare + NoDocbcCost + GenHlth + MentHlth + PhysHlth + DiffWalk + Sex + Education + Income\nmodel3 &lt;- train(formula_polynomial, data = trainData, method = \"glm\", family = \"binomial\",\n                trControl = train_control, metric = \"logLoss\")"
  },
  {
    "objectID": "Modelling.html#compare-models-using-cross-validation-with-log-loss",
    "href": "Modelling.html#compare-models-using-cross-validation-with-log-loss",
    "title": "Modelling",
    "section": "Compare Models Using Cross-Validation with Log Loss",
    "text": "Compare Models Using Cross-Validation with Log Loss\n\n# Compare Models Using Cross-Validation with Log Loss\nresamples &lt;- resamples(list(Basic = model1, Interaction = model2, Polynomial = model3))\n\n# Extract the mean log loss for each model\nlog_loss_results &lt;- resamples$values %&gt;%\n  select(Resample, contains(\"logLoss\")) %&gt;%\n  pivot_longer(cols = contains(\"logLoss\"), names_to = \"Model\", values_to = \"LogLoss\") %&gt;%\n  group_by(Model) %&gt;%\n  summarize(MeanLogLoss = mean(LogLoss, na.rm = TRUE))\n\n# Print the log loss results\nprint(log_loss_results)\n\n# A tibble: 3 × 2\n  Model               MeanLogLoss\n  &lt;chr&gt;                     &lt;dbl&gt;\n1 Basic~logLoss             0.321\n2 Interaction~logLoss       0.343\n3 Polynomial~logLoss        0.317\n\n# Determine the best model based on the lowest mean log loss\nbest_model_name &lt;- log_loss_results %&gt;% \n  filter(MeanLogLoss == min(MeanLogLoss)) %&gt;% \n  pull(Model)\n\n# Remove \"~logLoss\" from model names\nbest_model_name &lt;- gsub(\"~logLoss\", \"\", best_model_name)\n\n# List of models to compare\nmodels &lt;- list(Basic = model1, Interaction = model2, Polynomial = model3)\n\nThe model with the lowest log loss value is generally the best, as it indicates better performance in predicting class probabilities. Here the best performing model is the polynomial model."
  },
  {
    "objectID": "Modelling.html#evaluate-the-best-model-on-the-test-set",
    "href": "Modelling.html#evaluate-the-best-model-on-the-test-set",
    "title": "Modelling",
    "section": "Evaluate the Best Model on the Test Set",
    "text": "Evaluate the Best Model on the Test Set\n\n# Select the best model\nbest_model &lt;- models[[best_model_name]]\nprint(best_model)\n\nGeneralized Linear Model \n\n177577 samples\n    21 predictor\n     2 classes: 'X0', 'X1' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 142061, 142061, 142063, 142062, 142061 \nResampling results:\n\n  logLoss  \n  0.3165827\n\n# Evaluate the Best Model on the Test Set\npredictions &lt;- predict(best_model, newdata = testData, type = \"prob\")\n\n# Calculate log loss on the test set\n# Adjust the target names if needed\nactual &lt;- as.numeric(testData$Diabetes_binary) - 1\nlog_loss &lt;- -mean((actual == 1) * log(predictions[,2]) + \n                    (actual == 0) * log(1 - predictions[,2]))\nlog_loss\n\n[1] 0.3126407\n\n\nFINAL COMPARISION OF MODELS FOR LOG: IF IT WORKS KEEP THIS PART AND DELETE FROM 112-120\n\n# Evaluate the Best Logistic Regression Models on the Test Set\n# For model1\npredictions1 &lt;- predict(model1, newdata = testData, type = \"prob\")\nlog_loss1 &lt;- -mean((as.numeric(testData$Diabetes_binary) - 1) * log(predictions1[,2]) +\n                    (as.numeric(testData$Diabetes_binary) == 0) * log(1 - predictions1[,2]))\n\n# For model2\npredictions2 &lt;- predict(model2, newdata = testData, type = \"prob\")\nlog_loss2 &lt;- -mean((as.numeric(testData$Diabetes_binary) - 1) * log(predictions2[,2]) +\n                    (as.numeric(testData$Diabetes_binary) == 0) * log(1 - predictions2[,2]))\n\n# For model3\npredictions3 &lt;- predict(model3, newdata = testData, type = \"prob\")\nlog_loss3 &lt;- -mean((as.numeric(testData$Diabetes_binary) - 1) * log(predictions3[,2]) +\n                    (as.numeric(testData$Diabetes_binary) == 0) * log(1 - predictions3[,2]))\n\n# Store log losses\nlog_loss_lr &lt;- c(log_loss1, log_loss2, log_loss3)\nnames(log_loss_lr) &lt;- c(\"Basic\", \"Interaction\", \"Polynomial\")"
  },
  {
    "objectID": "Modelling.html#classification-tree",
    "href": "Modelling.html#classification-tree",
    "title": "Modelling",
    "section": "Classification Tree",
    "text": "Classification Tree\nA classification tree is a decision tree used for categorizing data into classes. It is a supervised learning model that splits the data into subsets based on the values of input features. The goal is to create a model that predicts the class label of new observations based on the values of their features. The tree structure consists of nodes that represent features, branches that represent decision rules, and leaves that represent the outcome or class label.\nHow it works: Splitting: At each node in the tree, the data is split based on the feature that best separates the classes. This split is determined by criteria such as Gini impurity, entropy, or information gain. Recursive Partitioning: The splitting process is repeated recursively on each subset of the data until a stopping criterion is met, such as a maximum tree depth, a minimum number of samples per leaf, or an improvement threshold. Pruning: To prevent overfitting, trees are often pruned by removing branches that provide little additional power to classify instances. This is done by setting a complexity parameter that controls the trade-off between tree size and fit to the training data.\n\n# Function to create and evaluate classification tree models\ncreate_and_evaluate_tree &lt;- function(formula, trainData, testData, cp_values) {\n  results &lt;- data.frame(CP = numeric(), Accuracy = numeric())\n  \n  for (cp in cp_values) {\n    model_tree &lt;- rpart(formula, data = trainData, method = \"class\", control = rpart.control(minbucket = 20, cp = cp))\n    \n    # Predict on the test set\n    predictions &lt;- predict(model_tree, testData, type = \"class\")\n    \n    # Confusion matrix to evaluate the model\n    conf_matrix &lt;- confusionMatrix(predictions, testData$Diabetes_binary)\n    \n    # Store accuracy\n    accuracy &lt;- conf_matrix$overall['Accuracy']\n    results &lt;- rbind(results, data.frame(CP = cp, Accuracy = accuracy))\n  }\n  \n  # Find the best cp based on maximum accuracy\n  best_cp &lt;- results$CP[which.max(results$Accuracy)]\n  print(paste0(\"Optimal Complexity Parameter: \", best_cp))\n  \n  # Fit the final model using the best cp value\n  final_tree &lt;- rpart(formula, data = trainData, method = \"class\", control = rpart.control(minbucket = 20, cp = best_cp))\n  \n  # Plot the tree\n  par(mar = c(1, 1, 1, 1))  # Adjust margins (bottom, left, top, right)\n  rpart.plot(final_tree, type = 2, extra = 104, fallen.leaves = TRUE, main = paste(\"Classification Tree for\", deparse(formula)))\n  \n  # Print the final confusion matrix for the best model\n  final_predictions &lt;- predict(final_tree, testData, type = \"class\")\n  final_conf_matrix &lt;- confusionMatrix(final_predictions, testData$Diabetes_binary)\n  print(final_conf_matrix)\n  \n  return(list(tree = final_tree, accuracy = max(results$Accuracy)))\n}\n\n# Define complexity parameter values to try\ncp_values &lt;- seq(0.000, 0.004, by = 0.001)\n\n# Model 1 Classification Tree\nset.seed(13579)\nformula1 &lt;- Diabetes_binary ~ .\ntree1 &lt;- create_and_evaluate_tree(formula1, trainData, testData, cp_values)\n\n[1] \"Optimal Complexity Parameter: 0.001\"\n\n\n\n\n\n\n\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    X0    X1\n        X0 64696  9379\n        X1   804  1224\n                                          \n               Accuracy : 0.8662          \n                 95% CI : (0.8638, 0.8686)\n    No Information Rate : 0.8607          \n    P-Value [Acc &gt; NIR] : 5.056e-06       \n                                          \n                  Kappa : 0.1561          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9877          \n            Specificity : 0.1154          \n         Pos Pred Value : 0.8734          \n         Neg Pred Value : 0.6036          \n             Prevalence : 0.8607          \n         Detection Rate : 0.8501          \n   Detection Prevalence : 0.9734          \n      Balanced Accuracy : 0.5516          \n                                          \n       'Positive' Class : X0              \n                                          \n\n# Model 2 Classification Tree\nset.seed(13579)\nformula2 &lt;- Diabetes_binary ~ HighBP + HighChol + CholCheck + BMI + Smoker + Stroke + HeartDiseaseorAttack \ntree2 &lt;- create_and_evaluate_tree(formula2, trainData, testData, cp_values)\n\n[1] \"Optimal Complexity Parameter: 0.001\"\n\n\n\n\n\n\n\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    X0    X1\n        X0 64751  9640\n        X1   749   963\n                                         \n               Accuracy : 0.8635         \n                 95% CI : (0.861, 0.8659)\n    No Information Rate : 0.8607         \n    P-Value [Acc &gt; NIR] : 0.01255        \n                                         \n                  Kappa : 0.1224         \n                                         \n Mcnemar's Test P-Value : &lt; 2e-16        \n                                         \n            Sensitivity : 0.98856        \n            Specificity : 0.09082        \n         Pos Pred Value : 0.87041        \n         Neg Pred Value : 0.56250        \n             Prevalence : 0.86068        \n         Detection Rate : 0.85083        \n   Detection Prevalence : 0.97750        \n      Balanced Accuracy : 0.53969        \n                                         \n       'Positive' Class : X0             \n                                         \n\n# Model 3 Classification Tree\nset.seed(13579)\nformula3 &lt;- Diabetes_binary ~ poly(BMI, 2) + poly(Age, 2) + HighBP + HighChol + CholCheck + Smoker + Stroke + HeartDiseaseorAttack + PhysActivity + Fruits + Veggies + HvyAlcoholConsump + AnyHealthcare + NoDocbcCost + GenHlth + MentHlth + PhysHlth + DiffWalk + Sex + Education + Income\ntree3 &lt;- create_and_evaluate_tree(formula3, trainData, testData, cp_values)\n\n[1] \"Optimal Complexity Parameter: 0.001\"\n\n\n\n\n\n\n\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    X0    X1\n        X0 64696  9379\n        X1   804  1224\n                                          \n               Accuracy : 0.8662          \n                 95% CI : (0.8638, 0.8686)\n    No Information Rate : 0.8607          \n    P-Value [Acc &gt; NIR] : 5.056e-06       \n                                          \n                  Kappa : 0.1561          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9877          \n            Specificity : 0.1154          \n         Pos Pred Value : 0.8734          \n         Neg Pred Value : 0.6036          \n             Prevalence : 0.8607          \n         Detection Rate : 0.8501          \n   Detection Prevalence : 0.9734          \n      Balanced Accuracy : 0.5516          \n                                          \n       'Positive' Class : X0              \n                                          \n\n# Compare the accuracy of the three classification tree models\naccuracies &lt;- c(tree1$accuracy, tree2$accuracy, tree3$accuracy)\nbest_tree_index &lt;- which.max(accuracies)\nbest_tree_model &lt;- list(tree1, tree2, tree3)[[best_tree_index]]\n\n# Print the best classification tree model\nprint(\"The best classification tree model is:\")\n\n[1] \"The best classification tree model is:\"\n\nprint(best_tree_model$tree)\n\nn= 177577 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n   1) root 177577 24743 X0 (0.8606633 0.1393367)  \n     2) HighBP&lt; 0.5 101219  6167 X0 (0.9390727 0.0609273) *\n     3) HighBP&gt;=0.5 76358 18576 X0 (0.7567249 0.2432751)  \n       6) GenHlth&lt; 3.5 56188 10556 X0 (0.8121307 0.1878693) *\n       7) GenHlth&gt;=3.5 20170  8020 X0 (0.6023798 0.3976202)  \n        14) BMI&lt; 27.5 6931  1891 X0 (0.7271678 0.2728322) *\n        15) BMI&gt;=27.5 13239  6129 X0 (0.5370496 0.4629504)  \n          30) HighChol&lt; 0.5 4134  1457 X0 (0.6475568 0.3524432) *\n          31) HighChol&gt;=0.5 9105  4433 X1 (0.4868753 0.5131247)  \n            62) BMI&lt; 34.5 5211  2383 X0 (0.5426981 0.4573019)  \n             124) Age&lt; 6.5 530   161 X0 (0.6962264 0.3037736) *\n             125) Age&gt;=6.5 4681  2222 X0 (0.5253151 0.4746849)  \n               250) HvyAlcoholConsump&gt;=0.5 128    30 X0 (0.7656250 0.2343750) *\n               251) HvyAlcoholConsump&lt; 0.5 4553  2192 X0 (0.5185592 0.4814408)  \n                 502) GenHlth&lt; 4.5 3162  1455 X0 (0.5398482 0.4601518) *\n                 503) GenHlth&gt;=4.5 1391   654 X1 (0.4701653 0.5298347)  \n                  1006) HeartDiseaseorAttack&lt; 0.5 767   358 X0 (0.5332464 0.4667536)  \n                    2012) PhysHlth&gt;=15.5 581   249 X0 (0.5714286 0.4285714) *\n                    2013) PhysHlth&lt; 15.5 186    77 X1 (0.4139785 0.5860215) *\n                  1007) HeartDiseaseorAttack&gt;=0.5 624   245 X1 (0.3926282 0.6073718) *\n            63) BMI&gt;=34.5 3894  1605 X1 (0.4121726 0.5878274) *\n\n\nIF THIS WORKS JUST FINE THEN DELETE 217-224\n\n# Evaluate the Best Classification Tree Models on the Test Set\n# For tree1\npredictions_tree1 &lt;- predict(tree1$tree, newdata = testData, type = \"class\")\naccuracy_tree1 &lt;- confusionMatrix(predictions_tree1, testData$Diabetes_binary)$overall['Accuracy']\n\n# For tree2\npredictions_tree2 &lt;- predict(tree2$tree, newdata = testData, type = \"class\")\naccuracy_tree2 &lt;- confusionMatrix(predictions_tree2, testData$Diabetes_binary)$overall['Accuracy']\n\n# For tree3\npredictions_tree3 &lt;- predict(tree3$tree, newdata = testData, type = \"class\")\naccuracy_tree3 &lt;- confusionMatrix(predictions_tree3, testData$Diabetes_binary)$overall['Accuracy']\n\n# Store accuracies\naccuracy_tree &lt;- c(accuracy_tree1, accuracy_tree2, accuracy_tree3)\nnames(accuracy_tree) &lt;- c(\"Basic\", \"Interaction\", \"Polynomial\")"
  },
  {
    "objectID": "Modelling.html#model-2-logistic-regression-with-few-cardiohealth-terms.",
    "href": "Modelling.html#model-2-logistic-regression-with-few-cardiohealth-terms.",
    "title": "Modelling",
    "section": "Model 2: Logistic regression with few cardiohealth terms.",
    "text": "Model 2: Logistic regression with few cardiohealth terms.\n\n# Model 2: Logistic Regression with only select few cardiohealth terms\nformula_interaction &lt;- Diabetes_binary ~ HighBP + HighChol + CholCheck + BMI + Smoker + Stroke + HeartDiseaseorAttack \nmodel2 &lt;- train(formula_interaction, data = trainData, method = \"glm\", family = \"binomial\",\n                trControl = train_control, metric = \"logLoss\")"
  },
  {
    "objectID": "Modelling.html#model-3-logistic-regression-with-polynomial-terms-and-all-terms.",
    "href": "Modelling.html#model-3-logistic-regression-with-polynomial-terms-and-all-terms.",
    "title": "Modelling",
    "section": "Model 3: Logistic regression with polynomial terms and all terms.",
    "text": "Model 3: Logistic regression with polynomial terms and all terms.\n\n# Model 3: Logistic Regression with Polynomial Terms with all terms\nformula_polynomial &lt;- Diabetes_binary ~ poly(BMI, 2) + poly(Age, 2) + HighBP + HighChol + CholCheck + Smoker + Stroke + HeartDiseaseorAttack + PhysActivity + Fruits + Veggies + HvyAlcoholConsump + AnyHealthcare + NoDocbcCost + GenHlth + MentHlth + PhysHlth + DiffWalk + Sex + Education + Income\nmodel3 &lt;- train(formula_polynomial, data = trainData, method = \"glm\", family = \"binomial\",\n                trControl = train_control, metric = \"logLoss\")"
  },
  {
    "objectID": "Modelling.html#random-forest",
    "href": "Modelling.html#random-forest",
    "title": "Modelling",
    "section": "Random Forest",
    "text": "Random Forest\nWhat is a Random Forest? A random forest is an ensemble learning method used for classification, regression, and other tasks. It operates by constructing multiple decision trees during training and outputs the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\nKey characteristics of random forests:\nEnsemble Method: Combines multiple decision trees to improve the overall performance. Bagging (Bootstrap Aggregating): Each tree is trained on a random subset of the training data, which is sampled with replacement. Feature Randomness: During the splitting of each node, a random subset of features is chosen, ensuring that the trees are diverse and less correlated. Why Use Random Forests? Improved Accuracy: By aggregating multiple trees, random forests tend to improve prediction accuracy compared to individual decision trees. Reduced Overfitting: Decision trees can be prone to overfitting, especially on noisy data. Random forests mitigate this by averaging multiple trees, which reduces the variance. Robustness: Random forests are robust to outliers and noise in the data. Feature Importance: They provide insights into feature importance, which helps in understanding the impact of different features on the target variable.\n\n# Set seed for reproducibility\nset.seed(13579)\n\n# Import the data\ndiabetes_data &lt;- read_excel(\"~/Downloads/diabetes_binary_health_indicators_BRFSS2015.xlsm\")\n\n# Convert Diabetes_binary to a factor with two levels\ndiabetes_data$Diabetes_binary &lt;- factor(diabetes_data$Diabetes_binary, levels = c(0, 1))\n\n# Ensure that the factor levels have valid R names\nlevels(diabetes_data$Diabetes_binary) &lt;- make.names(levels(diabetes_data$Diabetes_binary))\n\n# Split the data into training (70%) and test (30%) sets\ntrainIndex &lt;- createDataPartition(diabetes_data$Diabetes_binary, p = 0.7, list = FALSE)\ntrainData &lt;- diabetes_data[trainIndex, ]\ntestData &lt;- diabetes_data[-trainIndex, ]\n\n# Fit the randomForest models\nformula1 &lt;- Diabetes_binary ~ .\nmodel_1_rf &lt;- randomForest(formula1, data = trainData, mtry = ncol(trainData) / 3, ntree = 20, importance = TRUE)\n\n# Model 2\nformula2 &lt;- Diabetes_binary ~ HighBP + HighChol + CholCheck + BMI + Smoker + Stroke + HeartDiseaseorAttack \nmodel_2_rf &lt;- randomForest(formula2, data = trainData, mtry = floor((ncol(trainData) - 1) / 3), ntree = 20, importance = TRUE)\n\n#Model 3\nformula3 &lt;- Diabetes_binary ~  HighBP + HighChol + CholCheck + Smoker + Stroke + HeartDiseaseorAttack + PhysActivity + Fruits + Veggies + HvyAlcoholConsump + AnyHealthcare + NoDocbcCost + GenHlth + MentHlth + PhysHlth + DiffWalk + Sex + Education + Income\nmodel_3_rf &lt;- randomForest(formula3, data = trainData, mtry = ncol(trainData) / 3, ntree = 20, importance = TRUE)\n\n# Predict probabilities\nmodel_1_rfProbs &lt;- predict(model_1_rf, newdata = dplyr::select(testData, -Diabetes_binary), type = \"prob\")\nmodel_2_rfProbs &lt;- predict(model_2_rf, newdata = dplyr::select(testData, -Diabetes_binary), type = \"prob\")\nmodel_3_rfProbs &lt;- predict(model_3_rf, newdata = dplyr::select(testData, -Diabetes_binary), type = \"prob\")\n\n# Evaluate the Best Random Forest Models on the Test Set\n# For rf1\npredictions_rf1 &lt;- ifelse(model_1_rfProbs[, 2] &gt; 0.5, \"X1\", \"X0\")\naccuracy_rf1 &lt;- confusionMatrix(factor(predictions_rf1, levels = levels(testData$Diabetes_binary)), testData$Diabetes_binary)\n\n# For rf2\npredictions_rf2 &lt;- ifelse(model_2_rfProbs[, 2] &gt; 0.5, \"X1\", \"X0\")\naccuracy_rf2 &lt;- confusionMatrix(factor(predictions_rf2, levels = levels(testData$Diabetes_binary)), testData$Diabetes_binary)\n\n# For rf3\npredictions_rf3 &lt;- ifelse(model_3_rfProbs[, 2] &gt; 0.5, \"X1\", \"X0\")\naccuracy_rf3 &lt;- confusionMatrix(factor(predictions_rf3, levels = levels(testData$Diabetes_binary)), testData$Diabetes_binary)\n\n# Store accuracies and other metrics\naccuracy_rf &lt;- list(\n  \"Basic\" = list(\n    Accuracy = accuracy_rf1$overall['Accuracy'],\n    Kappa = accuracy_rf1$overall['Kappa'],\n    Sensitivity = accuracy_rf1$byClass['Sensitivity'],\n    Specificity = accuracy_rf1$byClass['Specificity'],\n    Precision = accuracy_rf1$byClass['Precision'],\n    Recall = accuracy_rf1$byClass['Recall'],\n    F1 = accuracy_rf1$byClass['F1']\n  ),\n  \"High Chol\" = list(\n    Accuracy = accuracy_rf2$overall['Accuracy'],\n    Kappa = accuracy_rf2$overall['Kappa'],\n    Sensitivity = accuracy_rf2$byClass['Sensitivity'],\n    Specificity = accuracy_rf2$byClass['Specificity'],\n    Precision = accuracy_rf2$byClass['Precision'],\n    Recall = accuracy_rf2$byClass['Recall'],\n    F1 = accuracy_rf2$byClass['F1']\n  ),\n  \"Polynomial\" = list(\n    Accuracy = accuracy_rf3$overall['Accuracy'],\n    Kappa = accuracy_rf3$overall['Kappa'],\n    Sensitivity = accuracy_rf3$byClass['Sensitivity'],\n    Specificity = accuracy_rf3$byClass['Specificity'],\n    Precision = accuracy_rf3$byClass['Precision'],\n    Recall = accuracy_rf3$byClass['Recall'],\n    F1 = accuracy_rf3$byClass['F1']\n  )\n)\n\n# Extract accuracy values for comparison\nrf_accuracies &lt;- sapply(accuracy_rf, function(x) x$Accuracy)\n\n# Print the best random forest model based on accuracy\nprint(\"The best random forest model based on accuracy is:\")\n\n[1] \"The best random forest model based on accuracy is:\"\n\nbest_rf_model &lt;- names(which.max(rf_accuracies))\nprint(best_rf_model)\n\n[1] \"High Chol.Accuracy\"\n\n\nCompare All Models\n\nlog_loss_lr &lt;- c(LogisticRegressionBasic = 0.20, LogisticRegressionInteraction = 0.22, LogisticRegressionPolynomial = 0.21) # Placeholder values\naccuracy_tree &lt;- c(0.83, 0.85, 0.84) # Placeholder values for classification tree models\n\ncomparison &lt;- data.frame(\n  Model = c(\"Logistic Regression Basic\", \"Logistic Regression Interaction\", \"Logistic Regression Polynomial\",\n            \"Classification Tree Basic\", \"Classification Tree Interaction\", \"Classification Tree Polynomial\",\n            \"Random Forest Basic\", \"Random Forest High Chol\", \"Random Forest Polynomial\"),\n  LogLoss = c(log_loss_lr, rep(NA, 6)),\n  Accuracy = c(rep(NA, 3), accuracy_tree, rf_accuracies)\n)\n\n# Print the comparison table\nprint(comparison)\n\n                            Model LogLoss  Accuracy\n1       Logistic Regression Basic    0.20        NA\n2 Logistic Regression Interaction    0.22        NA\n3  Logistic Regression Polynomial    0.21        NA\n4       Classification Tree Basic      NA 0.8300000\n5 Classification Tree Interaction      NA 0.8500000\n6  Classification Tree Polynomial      NA 0.8400000\n7             Random Forest Basic      NA 0.8590726\n8         Random Forest High Chol      NA 0.8621605\n9        Random Forest Polynomial      NA 0.8547495\n\n# Determine the best model based on the metric\nbest_log_loss_model &lt;- names(which.min(log_loss_lr))\nbest_accuracy_model_tree &lt;- names(which.max(accuracy_tree))\nbest_accuracy_model_rf &lt;- names(which.max(rf_accuracies))\n\n# Output the best model based on log loss and accuracy\nprint(paste(\"Best Logistic Regression Model (based on log loss):\", best_log_loss_model))\n\n[1] \"Best Logistic Regression Model (based on log loss): LogisticRegressionBasic\"\n\nprint(paste(\"Best Classification Tree Model (based on accuracy):\", best_accuracy_model_tree))\n\n[1] \"Best Classification Tree Model (based on accuracy): \"\n\nprint(paste(\"Best Random Forest Model (based on accuracy):\", best_accuracy_model_rf))\n\n[1] \"Best Random Forest Model (based on accuracy): High Chol.Accuracy\"\n\n\nChoosing Winner\n\n# Create a detailed comparison table\ncomparison &lt;- data.frame(\n  Model = c(\"Logistic Regression Basic\", \"Logistic Regression Interaction\", \"Logistic Regression Polynomial\",\n            \"Classification Tree Basic\", \"Classification Tree Interaction\", \"Classification Tree Polynomial\",\n            \"Random Forest Basic\", \"Random Forest High Chol\", \"Random Forest Polynomial\"),\n  Accuracy = c(rep(NA, 3), accuracy_tree, rf_accuracies),\n  LogLoss = c(log_loss_lr, rep(NA, 6))\n)\n\n# Print the comparison table\nprint(comparison)\n\n                            Model  Accuracy LogLoss\n1       Logistic Regression Basic        NA    0.20\n2 Logistic Regression Interaction        NA    0.22\n3  Logistic Regression Polynomial        NA    0.21\n4       Classification Tree Basic 0.8300000      NA\n5 Classification Tree Interaction 0.8500000      NA\n6  Classification Tree Polynomial 0.8400000      NA\n7             Random Forest Basic 0.8590726      NA\n8         Random Forest High Chol 0.8621605      NA\n9        Random Forest Polynomial 0.8547495      NA\n\n# Choosing the best model based on accuracy\nbest_model_index &lt;- which.max(comparison$Accuracy)\nbest_model &lt;- comparison$Model[best_model_index]\n\n# Output the best overall model\nprint(paste(\"The best overall model based on accuracy is:\", best_model))\n\n[1] \"The best overall model based on accuracy is: Random Forest High Chol\""
  }
]